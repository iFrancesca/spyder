import wordcloud
import jieba
from imageio import imread
   #输入文件名
txt=open('''d:/python/spyder/文件/豆瓣电影_评论.txt''',encoding='utf-8').read()
words=jieba.lcut(txt)
counts={}
for word in words:
    #剔除不想要的词语
    if word in ['一个','就是','这个','自己','我们','可以','可能','没有','还是',\
                '所以','不是','已经','但是','那么','其实','他们','大家','觉得','因为'\
                ,'成为']:
        continue
         
    elif len(word)==1:
        continue
    else:
        counts[word]=counts.get(word,0)+1
items=list(counts.items())
items.sort(key=lambda x:x[1],reverse=True)
#可以自定义初始的dic
dic={'那个': 42, '知道': 49, '组织': 30, '中国': 78, '直接': 28, '身份': 33, '角色': 49, 'kiko': 30, '笑脸': 42, '案件': 47, '导演': 59, '如果': 49, '父亲': 32, '春节': 50, '真的': 30, '思诺': 75, '不过': 28, '上映': 53, '对于': 36, '而且': 50, '当然': 33, '时候': 40, '一起': 28, '案子': 40, '泰国': 72, '为了': 37, '剧情': 67, '第一部': 45, '怎么': 28, '宋义': 105, '不会': 41, '一些': 40, '唐人街': 209, '刘昊然': 47, '期待': 123, '一部': 31, '故事': 72, '秦风': 216, '这些': 34, '拍摄': 40, '凶手': 39, '第三部': 34, '电影': 230, '只是': 30, '第一': 34, '系列': 104, '日本': 71, '第二部': 47, '犯罪': 49, '林默': 90, '为什么': 28, '非常': 43, '分析': 33, '陈思诚': 83, '同时': 35, '探案': 175, '发现': 41, '票房': 51, '人物': 34, '杀人案': 32, '时间': 67, '宇宙': 62, '侦探': 165, '杀人': 33, '最后': 61, '还有': 48, '什么': 43, '一直': 36, '两部': 49, '王宝强': 44, '唐探': 289, '美国': 40, '2018': 63, '演员': 44, '野田': 48, '看到': 42, '推理': 83, '唐仁': 104, '这种': 30, '作为': 34, '虽然': 37, '网剧': 59, '出现': 62, '母亲': 29, '应该': 41, '两个': 34, '目前': 31, '问题': 35, '肖央': 32, '哈哈哈': 392, '破案': 36, '这样': 41, '开始': 44, '喜剧': 35, '元素': 28, '很多': 64, '以及': 33, '观众': 75, '饰演': 31, '东京': 54}

for i in range(100):
    word,count=items[i]
    print('{:<15}{:>5}'.format(word,count))
    
    dic[word]=dic.get(word,0)+count


mask=imread('fivestart.png')
w = wordcloud.WordCloud( \
    width = 1000, height = 700,\
    background_color = "white",
    font_path = "msyh.ttc",mask=mask    
    )
#按频率，否则使用w.generate(txt)
w.fit_words(dic)
#输入保存文件
w.to_file("唐探33.png")
